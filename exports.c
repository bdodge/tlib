/*
 *  Common interface for translation libraries.
 *
 *  Copyright (c) Antmicro
 *  Copyright (c) Realtime Embedded
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 2 of the License, or (at your option) any later version.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library; if not, see <http://www.gnu.org/licenses/>.
 */
#include <stdint.h>
#include "cpu.h"
#include "cpu-defs.h"
#include "tcg.h"
#include "tcg-additional.h"
#include "exec-all.h"

static tcg_t stcg;

static void init_tcg()
{
  stcg.ldb = __ldb_mmu;
  stcg.ldw = __ldw_mmu;
  stcg.ldl = __ldl_mmu;
  stcg.ldq = __ldq_mmu;
  stcg.stb = __stb_mmu;
  stcg.stw = __stw_mmu;
  stcg.stl = __stl_mmu;
  stcg.stq = __stq_mmu;
  tcg_attach(&stcg);
  set_temp_buf_offset(offsetof(CPUState, temp_buf));
  int i;
  for (i = 0; i < 7; i++)
  {
    set_tlb_table_n_0_rwa(i, offsetof(CPUState, tlb_table[i][0].addr_read), offsetof(CPUState, tlb_table[i][0].addr_write), offsetof(CPUState, tlb_table[i][0].addend));
    set_tlb_table_n_0(i, offsetof(CPUState, tlb_table[i][0]));
  }
  set_tlb_entry_addr_rwu(offsetof(CPUTLBEntry, addr_read), offsetof(CPUTLBEntry, addr_write), offsetof(CPUTLBEntry, addend));
  set_sizeof_CPUTLBEntry(sizeof(CPUTLBEntry));
  set_TARGET_PAGE_BITS(TARGET_PAGE_BITS);
  attach_malloc(tlib_malloc);
  attach_realloc(tlib_realloc);
  attach_free(tlib_free);
}

uint32_t maximum_block_size;
uint32_t size_of_next_block_to_translate;

uint32_t tlib_set_maximum_block_size(uint32_t size)
{
  uint32_t effective_value;

  effective_value = size & CF_COUNT_MASK;
  maximum_block_size = effective_value;
  return effective_value;
}

uint32_t tlib_get_maximum_block_size()
{
  return maximum_block_size;
}

void gen_helpers(void);

int32_t tlib_init(char *cpu_name)
{
  init_tcg();
  CPUState *env = tlib_mallocz(sizeof(CPUState));
  cpu_exec_init(env);
  cpu_exec_init_all();
  gen_helpers();
  translate_init();
  if (cpu_init(cpu_name) != 0) {
      tlib_free(env);
      return -1;
  }
  tlib_set_maximum_block_size(0x7FF);
  env->atomic_memory_state = NULL;
  return 0;
}

void tlib_atomic_memory_state_init(int id, uintptr_t atomic_memory_state_ptr)
{
  cpu->id = id;
  cpu->atomic_memory_state = (atomic_memory_state_t*)atomic_memory_state_ptr;
  register_in_atomic_memory_state(cpu->atomic_memory_state, id);
}

static void free_phys_dirty()
{
  if(dirty_ram.phys_dirty) {
    tlib_free(dirty_ram.phys_dirty);
  }
}

void tlib_dispose()
{
  tlib_arch_dispose();
  code_gen_free();
  free_all_page_descriptors();
  free_phys_dirty();
  tlib_free(cpu);
  tcg_dispose();
}

// this function returns number of instructions executed since the previous call
// there is `cpu->instructions_count_total_value` that contains the cumulative value
uint64_t tlib_get_executed_instructions()
{
  uint64_t result = cpu->instructions_count_value;
  cpu->instructions_count_value = 0;
  cpu->instructions_count_threshold -= result;
  return result;
}

// `TranslationCPU` uses the number of executed instructions to calculate the elapsed virtual time.
// This number is divided by `PerformanceInMIPS` value, but may leave a remainder, that is not reflected in `TranslationCPU` state.
// To account for that, we have to report this remainder back to tlib, so that the next call to `tlib_get_executed_instructions`
// includes it in the returned value.
void tlib_reset_executed_instructions(uint64_t val)
{
  cpu->instructions_count_value = val;
  cpu->instructions_count_threshold += val;
}

uint64_t tlib_get_total_executed_instructions()
{
  return cpu->instructions_count_total_value;
}

void tlib_reset()
{
  cpu_reset(cpu);
}

int32_t tlib_execute(int32_t max_insns)
{
  if(cpu->instructions_count_value != 0)
  {
    tlib_abortf("Tried to execute cpu without reading executed instructions count first.");
  }
  cpu->instructions_count_threshold = max_insns;
  return cpu_exec(cpu);
}

int tlib_restore_context(void);

extern void *global_retaddr;

void tlib_restart_translation_block()
{
  target_ulong pc, cs_base;
  int cpu_flags;
  TranslationBlock *tb;
  int executed_instructions = -1;

  tb = tb_find_pc((uintptr_t)global_retaddr);
  if(tb != 0)
  {
    executed_instructions = cpu_restore_state_and_restore_instructions_count(cpu, tb, (uintptr_t)global_retaddr);
  }

  cpu_get_tb_cpu_state(cpu, &pc, &cs_base, &cpu_flags);
  tb_phys_invalidate(cpu->current_tb, -1);
  tb_gen_code(cpu, pc, cs_base, cpu_flags, 0);

  if(cpu->block_finished_hook_present)
  {
      tlib_on_block_finished(pc, executed_instructions);
  }

  cpu->exception_index = EXCP_WATCHPOINT;
  longjmp(cpu->jmp_env, 1);  //for watchpoints!
}

void tlib_set_return_request()
{
  cpu->exit_request = 1;
}

int32_t tlib_is_wfi()
{
     return cpu->wfi;
}

uint32_t tlib_get_page_size()
{
  return TARGET_PAGE_SIZE;
}

void tlib_map_range(uint64_t start_addr, uint64_t length)
{
  ram_addr_t phys_offset = start_addr;
  ram_addr_t size = length;
  //remember that phys_dirty covers the whole memory range from 0 to the end
  //of the registered memory. Most offsets are probably unused. When a new
  //region is registered before any already registered memory, the array
  //does not need to be expanded.
  uint8_t *phys_dirty;
  size_t array_start_addr, array_size, new_size;
  array_start_addr = start_addr >> TARGET_PAGE_BITS;
  array_size = size >> TARGET_PAGE_BITS;
  new_size = array_start_addr + array_size;
  if(new_size > dirty_ram.current_size)
  {
    phys_dirty = tlib_malloc(new_size);
    memcpy(phys_dirty, dirty_ram.phys_dirty, dirty_ram.current_size);
    if(dirty_ram.phys_dirty != NULL)
    {
      tlib_free(dirty_ram.phys_dirty);
    }
    dirty_ram.phys_dirty = phys_dirty;
    dirty_ram.current_size = new_size;
  }
  memset(dirty_ram.phys_dirty + array_start_addr, 0xff, array_size);
  cpu_register_physical_memory(start_addr, size, phys_offset | IO_MEM_RAM);
}

void tlib_unmap_range(uint64_t start, uint64_t end)
{
  uint64_t new_start;

  while(start <= end)
  {
    unmap_page(start);
    new_start = start + TARGET_PAGE_SIZE;
    if(new_start < start)
    {
      return;
    }
    start = new_start;
  }
}

uint32_t tlib_is_range_mapped(uint64_t start, uint64_t end)
{
  PhysPageDesc *pd;

  while(start < end)
  {
    pd = phys_page_find((target_phys_addr_t)start >> TARGET_PAGE_BITS);
    if(pd != NULL && pd->phys_offset != IO_MEM_UNASSIGNED)
    {
      return 1; // at least one page of this region is mapped
    }
    start += TARGET_PAGE_SIZE;
  }
  return 0;
}

void tlib_invalidate_translation_blocks(uintptr_t start, uintptr_t end)
{
  tb_invalidate_phys_page_range_inner(start, end, 0, 0);
}

uint64_t tlib_translate_to_physical_address(uint64_t address)
{
  return virt_to_phys(address);
}

void tlib_set_irq(int32_t interrupt, int32_t state)
{
  if(state)
  {
    cpu_interrupt(cpu, interrupt);
  }
  else
  {
    cpu_reset_interrupt(cpu, interrupt);
  }
}

int32_t tlib_is_irq_set()
{
  return cpu->interrupt_request;
}

void tlib_add_breakpoint(uint64_t address)
{
  cpu_breakpoint_insert(cpu, address, BP_GDB, NULL);
}

void tlib_remove_breakpoint(uint64_t address)
{
  cpu_breakpoint_remove(cpu, address, BP_GDB);
}

uintptr_t translation_cache_size;

void tlib_set_translation_cache_size(uintptr_t size)
{
  translation_cache_size = size;
}

void tlib_invalidate_translation_cache()
{
  if(cpu)
  {
    tb_flush(cpu);
  }
}

int tlib_restore_context()
{
  uintptr_t pc;
  TranslationBlock *tb;

  pc = (uintptr_t)global_retaddr;
  tb = tb_find_pc(pc);
  if(tb == 0)
  {
    // this happens when PC is outside RAM or ROM
    return -1;
  }
  return cpu_restore_state(cpu, tb, pc);
}

void* tlib_export_state()
{
  return cpu;
}

int32_t tlib_get_state_size()
{
  // Cpu state size is reported as
  // an offset of `current_tb` field
  // provided by CPU_COMMON definition.
  // It is a convention that all
  // architecture-specific, non-pointer
  // fields should be located in this
  // range. As a result this size can
  // be interpreted as an amount of bytes
  // to store during serialization.
  return (ssize_t)(&((CPUState *) 0)->current_tb);
}

void tlib_set_chaining_enabled(uint32_t val)
{
  cpu->chaining_disabled = !val;
}

uint32_t tlib_get_chaining_enabled()
{
  return !cpu->chaining_disabled;
}

void tlib_set_tb_cache_enabled(uint32_t val)
{
    cpu->tb_cache_disabled = !val;
}

uint32_t tlib_get_tb_cache_enabled()
{
    return !cpu->tb_cache_disabled;
}

void tlib_set_block_finished_hook_present(uint32_t val)
{
  cpu->block_finished_hook_present = !!val;
}

void tlib_set_block_begin_hook_present(uint32_t val)
{
  cpu->block_begin_hook_present = !!val;
}

int32_t tlib_set_return_on_exception(int32_t value)
{
    int32_t previousValue = cpu->return_on_exception;
    cpu->return_on_exception = !!value;
    return previousValue;
}

void tlib_flush_page(uint64_t address)
{
    tlb_flush_page(cpu, address);
}

#if TARGET_LONG_BITS == 32
uint32_t* get_reg_pointer_32(int reg_number);
#elif TARGET_LONG_BITS == 64
uint64_t* get_reg_pointer_64(int reg_number);
#else
#error "Unknown number of bits"
#endif

uint64_t tlib_get_register_value(int reg_number)
{
#if TARGET_LONG_BITS == 32
    uint32_t* ptr = get_reg_pointer_32(reg_number);
    if(ptr == NULL)
    {
        tlib_abortf("Write to undefined CPU register number %d detected", reg_number);
        return 0;
    }
    return (uint64_t)*ptr;
#elif TARGET_LONG_BITS == 64
    uint64_t* ptr = get_reg_pointer_64(reg_number);
    if(ptr == NULL)
    {
        tlib_abortf("Write to undefined CPU register number %d detected", reg_number);
        return 0;
    }
    return *ptr;
#else
#error "Unknown number of bits"
#endif
}

void tlib_set_register_value(int reg_number, uint64_t val)
{
#if TARGET_LONG_BITS == 32
    uint32_t* ptr = get_reg_pointer_32(reg_number);
    if(ptr == NULL)
    {
        tlib_abortf("Write to undefined CPU register number %d detected", reg_number);
        return;
    }
    *ptr = val & 0xFFFFFFFF;
#elif TARGET_LONG_BITS == 64
    uint64_t* ptr = get_reg_pointer_64(reg_number);
    if(ptr == NULL)
    {
        tlib_abortf("Write to undefined CPU register number %d detected", reg_number);
        return;
    }
    *ptr = val;
#else
#error "Unknown number of bits"
#endif
}

